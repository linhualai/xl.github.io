<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
    <title>Posts</title>
    <link href="http://veryr.com/atom.xml" rel="self" />
    <link href="http://veryr.com" />
    <id>http://veryr.com/atom.xml</id>
    <author>
        <name>Linhua Lai</name>
        <email>linhua.lai@gmail.com</email>
    </author>
    <updated>2013-12-06T00:00:00Z</updated>
    <entry>
    <title>Warp : Haskell 的高性能 Web 服务器(译文)</title>
    <link href="http://veryr.com/posts/warp/" />
    <id>http://veryr.com/posts/warp/</id>
    <published>2013-12-06T00:00:00Z</published>
    <updated>2013-12-06T00:00:00Z</updated>
    <summary type="html"><![CDATA[<h2 id="按">按</h2>
<p>GHC 7.8 马上就要发布了。一个很大的改进就是加入了本文所说的并行 IO 管理器。从此之后 Haskell 在高性能服务器领域将不再会有对手。<code>nginx</code>和<code>Erlang</code>为无法撼动了。绝对在 c1000k 中遥遥领先。</p>
<p>Kazu Yamamoto 和 Michael Snoyman 是网络编程和高手，这篇文章讲述了他们创造荣耀的过程。我翻译想必是错误百出，建议英语过了三级的同学都去看原文，原文绝对精彩。原文在：<a href="http://aosabook.org/en/posa/warp.html">AOSA:Warp</a>。话说<a href="http://aosabook.org">AOSA</a>每篇文章都相当不错。</p>
<h1 id="warp">Warp</h1>
<p>作者: Kazu Yamamoto, Michael Snoyman and Andreas Voellmy</p>
<p>Warp 是 Haskell(一种纯函数式编程语言) 的一个高性能的 HTTP 服务器端程序库。Yesod 和 <code>mighty</code> 都是用 Warp 来实现的，Yesod 是一个 web 应用框架，<code>mighty</code> 则是一个 HTTP 服务器。我们做过测试，<code>mighty</code> 的性能可以与 <code>nginx</code> 相提并论了，这篇文章将会阐述 Warp 的架构以及为什么它能达到这样的性能。Warp能运行在 Linux，BSD 系列，Mac 和 Windows 上，但简单起见，我们只谈 Linux 环境。</p>
<h2 id="haskell-中的网络编程">Haskell 中的网络编程</h2>
<p>很多人会觉得 FP 语言都是慢如蜗牛而且很不实用。其实不然，Haskell 就提供的一个近于完美的网络编程方法，这得力于 Haskell 的旗舰编译器 GHC。GHC 提供了轻量且强健的用户态线程。这一节我们就来回顾一下常见的几种服务器端网络编程模型，然后和 Haskell 比较一下。我们得到的结论是：Haskell 的便捷的抽象能力让程序员第一次有机会编写出清晰，简单的代码，同时GHC 精致的多核运行时系统又能把代码的运行速度提高到和 NB 的 C 程序员手写优化过的代码一样快。这在以前是不可想象的。</p>
<h3 id="多线程">多线程</h3>
<p>传统的网络服务器程序会用多线程来处理并发。在这种架构下，每个连接会起一个系统线程或 OS 进程来处理。这一架构的变种也有用线程池的，也就是预先起一大堆线程(或进程)。Apache 是就是一个典型的例子。</p>
<figure>
<img src="https://raw.github.com/snoyberg/posa-chapter/master/1.png" alt="Native threads" /><figcaption>Native threads</figcaption>
</figure>
<p>这种架构是优点在于，开发者可以写出简单的代码，只需在熟悉的控制流下编写处理输入，生成输出的代码就行了。这种架构也能利用现代 CPU 的多核能力。其缺点则是连接数一多，系统进程，系统线程频频进行上下文切换，性能会下滑得很厉害。</p>
<h3 id="事件驱动">事件驱动</h3>
<p>高性能服务器领域，事件驱动模型最近变得很流行了。这个架构下，多个连接是用一个进程(线程)来处理的。lighttpd 是用这个架构的一下例子。</p>
<figure>
<img src="https://raw.github.com/snoyberg/posa-chapter/master/2.png" alt="Event driven" /><figcaption>Event driven</figcaption>
</figure>
<p>由于没有进程切换，上下文切换也就很少，性能自然也就上去了。这是其优点。</p>
<p>不过，这个架构也让网络编程变得异常复杂。这样说吧，事件驱动架构把程序的控制流反转了，程序员得把他们自然的逻辑分解重构成各种不阻塞的事件处理函数。程序员不能调用阻塞的 IO 函数，只能使用一些比较复杂的异步调用，常用的异常处理方法也不能用了。</p>
<h3 id="每核一进程">每核一进程</h3>
<p>很多聪明的家伙马上就想到了：在 N 个核的每个核上创建一个事件驱动的进程，每个进程称为一个 <em>worker</em>。这需要在多个进程之间共享一个端口，用预创建(Prefork)就可以共享端口。</p>
<p>传统的多进程方式下，有新的连接进来了才 fork，预创建的话连接还没进来就先创建好进程了。这个 Prefork 和 Apache 的 prefork 模式名字一样，但其实不是一回事。</p>
<figure>
<img src="https://raw.github.com/snoyberg/posa-chapter/master/3.png" alt="One process per core" /><figcaption>One process per core</figcaption>
</figure>
<p><code>nginx</code> 用的就是这个架构。Node.js 从前只用事件驱动，现在它也实现了这种预创建的技术。不过这种技术无法解决程序不易读写的问题，还是有很多的回调函数要写。</p>
<h3 id="用户态线程">用户态线程</h3>
<p>GHC 的用户态线程可以解决程序结构不清晰的问题。具体来说，我们可以为每一个 HTTP 连接创建一个用户态线程。每个用户态线程的处理逻辑和传统的阻塞方式一样。我们的程序又回到朴素的简单的状态，但是 GHC 又能将我们的代码转换成复杂的异步 IO，并跑在多个核上。</p>
<p>深入一点细节的话，GHC 把用户态线程分用到少量的系统线程上。GHC 的多核运动时能轻巧的调度海量用户态线程，不会引起系统级上下文切换。</p>
<p>GHC 的用户态线程是很轻量的，当代的机器跑 100000 个用户线程是毫无压力。而且相当健壮，异步的异常也完全搞定。见<a href="#warp-的架构">Warp 的架构</a> 和 <a href="#文件描述符计时器">文件描述符计时器</a>。此外，GHC 的调度器能在多核之间做负载均衡调度，充分作用多核。</p>
<p>用户调用的接口，逻辑上是阻塞的 IO 调用，比如读写 socket，实际上最终运行的是异步版本的 IO 调用：如果此次调用数据 ready 的话，用户线程当然不阻塞直接继续运行了；如果数据不 ready 需要等待的话，线程实际上在其需要的数据条件上注册一下告诉调度器说它在等这个事件。调度器会监测各种 IO 事件并通知各等待着的线程，让他们重新运行起来。这一切都发生在 Haskell 的运行时，对用户是透明的，完全不用程序员参与。</p>
<p>Haskell 里面几乎所有数据结构都是不可修改的，这也意味着，多数函数都是线程安全的。GHC 在什么是时候会切换用户线程呢？答案是在分配内存的时候。Haskell 的数据不可修改使得实际上新的数据，新的内存是不停的在分配的，所以这个粒度是足够的。不明白的话可以参看一下：<a href="http://www.aosabook.org/en/ghc.html">such data allocation occurs regularly enough for context switching</a>。</p>
<p>在 Haskell 之前其实有很多语言已经实现用户态线程了，但它们得到广泛应用可能是因为要么不轻量，要么不健壮。另外有些语言则是实现了协程(coroutine)库，协程调度则是非抢占(non-preemptive)式的。Erlang 和 Haskell 一样，提供的是轻量级线程，Go 语言则使用轻量级协程(goroutine)。</p>
<p>作者写这篇文章的时候 <code>mighty</code> 使用 prefork 技术来利用多核，因为 Warp 还不支持。下图展示了这一架构。每个用户连接用一个用户态线程来处理，每个用户态线程又是在一个系统线程上跑，N 个核上又跑着 N 个系统线程。 <img src="https://raw.github.com/snoyberg/posa-chapter/master/4.png" alt="User threads with one process per core" /></p>
<p>我们发现 GHC 运动时库中的 IO manager 组件是一个性能瓶颈。为了解决这个问题，我们开发了一版 <code>parallel IO manager</code>，通过在每个核上都跑一个事件注册表和事件监测器极大的提升了在多核上的可扩展性。使用了这个并行 IO 调度器的 Haskell 程序跑在多核上时，会起多个 OI 调度器来利用多核。每个用户态线程会被调度到其中的一下核上。</p>
<figure>
<img src="https://raw.github.com/snoyberg/posa-chapter/master/5.png" alt="User threads in a sigle process" /><figcaption>User threads in a sigle process</figcaption>
</figure>
<p>会包含这个新的并行 IO 调度器的 GHC 新版本会在 2013 年秋天发布(译者注：已然跳票，我都要穿冬衣了也还没用上 7.8)。Warp 不用任何修改就能用上多核了，<code>mighty</code> 用的 prefork 也可以退修了。</p>
<h2 id="warp-的架构">Warp 的架构</h2>
<p>Warp 是个网络应用接口(Web Application Interface，WAI) 的引擎。它运行在 HTTP 协议上的 WAI 应用。上面提到的 Yesod 和 <code>mighty</code> 就是 WAI 应用的例子。</p>
<figure>
<img src="https://raw.github.com/snoyberg/posa-chapter/master/wai.png" alt="Web Application Interface (WAI)" /><figcaption>Web Application Interface (WAI)</figcaption>
</figure>
<p>WAI 应用的类型如下：</p>
<pre><code>type Application = Request -&gt; ResourceT IO Response</code></pre>
<p>Haskell 中，函数的参数类型是用右向箭头隔开的，最右边的一个类型则是函数的返回类型。上面的定义的含义是：WAI 应用接收一个 <code>Request</code> 并返回一个 <code>Response</code>，<code>ResouceT IO</code> 表示这个地方可能需求用到可控的 IO。</p>
<p>一个连接过来后，一个专门的用户态线程就会创建(spawn)来处理之。这个线程先接收客户端的 HTTP 请求，解析成一下<code>Request</code>，然后 Warp 把这个<code>Request</code> 传给这个 WAI 应用，并等待它的一个<code>Response</code>返回。最后，Warp 根据<code>Response</code>生成 HTTP 返回，并通过网络发送给客户端。如下图。</p>
<figure>
<img src="https://raw.github.com/snoyberg/posa-chapter/master/warp.png" alt="The architecture of Warp" /><figcaption>The architecture of Warp</figcaption>
</figure>
<p>用户线程不断的重复上面的步骤，直到该连接被客户端或者收到了错误的请求，或者这个用户线程很久没有收到一定量网络数据，也会被一个特殊的管理线程给喀嚓掉。</p>
<h2 id="warp-的性能表现">Warp 的性能表现</h2>
<p>在介绍我们如何改善了 Warp 的性能前呢，我们先来看一下我们优化后的结果。下面的结果是用 2.8.4 的<code>mighty</code>(采用 Warp 1.3.8.1) 和 1.4.0 的<code>nginx</code>跑出来的。</p>
<p>压测的环境如下：</p>
<ul>
<li>1Gpbs 以太网连接的 “12 核” 两台机器(Intel Xeon E5645, 双网卡, 每个 CPU 带 5 个核) connected with 1Gpbs Ethernet</li>
<li>一台运行 Linux 3.2.0(Ubuntu 12.04 LTS)</li>
<li>另一台跑的是 FreeBSD 9.1</li>
</ul>
<p>测试工具我们用过不少，早前我们用的是<code>httperf</code>，不过我们发现其用的是<code>select</code>调用，而且是单线程的，很快就测试就跟不上多核 HTTP 服务器的性能了。所以你们就切换到<code>weighttp</code>上，它用的是<code>libev</code>(和 epoll 是一路的)能跑在多核上。在 FreeBSD 上我们这样起了一个<code>weighttp</code>：</p>
<pre><code>weighttp -n 100000 -c 1000 -t 10 -k http://&lt;ip_address&gt;:&lt;port_number&gt;/</code></pre>
<p>这样我们就用 10 个线程起了 1000 个 HTTP 连接，每个连接发送 100 个请求来测试。</p>
<p>被测试的网络服务器则是跑在 Linux 上。对于每个请求，它返回一个<code>index.html</code>。用的是<code>nginx</code>的默认<code>index.html</code>，大小为 151 字节。</p>
<p>Linux/FreeBSD 都有许多参数可以调。需求仔细调一下这样参数。<a href="http://gwan.com/en_apachebench_httperf.html">ApacheBench &amp; HTTPerf</a>是一个不错的教程。对<code>mighty</code>和<code>nginx</code>下面的东东一定是要调一下的：</p>
<ul>
<li>打开文件描述符缓存</li>
<li>关闭日志</li>
<li>关闭限速</li>
</ul>
<p>跑的结果：</p>
<figure>
<img src="https://raw.github.com/snoyberg/posa-chapter/master/benchmark.png" alt="Performance of Warp and nginx" /><figcaption>Performance of Warp and <code>nginx</code></figcaption>
</figure>
<p>x 轴是 worker 数，y 轴是每秒的吞吐量。</p>
<ul>
<li><p>mighty 2.8.4 (GHC 7.7): 用 GHC 7.7.20130504 (可以看成是 GHC 7.8)编译的。用上了并行的 IO manager，只起了一个 worker。给 GHC 的运行时参数是<code>+RTS -qa -A128m -N&lt;x&gt;</code>， <x> 是机器核娄，128m 是 GC 的内存分配空间大小。</p></li>
<li><p>mighty 2.8.4 (GHC 7.6.3): 用当前稳定版 GHC 7.6.3 编译的结果。</p></li>
</ul>
<h2 id="关键点">关键点</h2>
<p>在实现高性能的 Haskell 服务器上我们总结了 4 个关键点：</p>
<ol type="1">
<li>系统调用调得越少越好</li>
<li>减少重复计算，优化每个函数实现</li>
<li>不要用锁</li>
<li>使用正确的数据结构很重要</li>
</ol>
<h3 id="系统调用调得越少越好">系统调用调得越少越好</h3>
<p>尽管系统调用在现代操作系统上一般都不怎么耗时，但只要调用得够多，也能成为一个大问题。实际上 Warp 处理每个请求调用了几个系统调用，有用<code>recv()</code>，<code>send()</code>和<code>sendfile()</code> (这货能让文件拷贝一点不走用户空间)。其他的系统调用如<code>open()</code>，<code>stat()</code>，<code>close()</code> 就被优化掉了。下面有一节 (<a href="#文件描述符计时器">文件描述符计时器</a>) 会再说这个细节。</p>
<p>我们用<code>strace</code>命令来跟踪最后调的系统调用。我们发现<code>nginx</code>居然用了一个我们不知道的<code>accept4</code>。</p>
<p>在 Haskell 的标准网络库里，监听一个 socket 是会用上非阻塞的标志的，不过新连接过来时也要将这个进来的 socket 再设置一下这个非阻塞标志。标准库是这么搞的：调用了两次<code>fcntl()</code>，一次获取当前标志，另一次再设置新的非阻塞标志。</p>
<p>Linux 下即使监听的 socket 是有非阻塞标志，新连接过来的 socket 也是默认不设置非阻塞标志的。<code>accept()</code>已经是这样的了，所以就有这个<code>accept4()</code>，它可以在新连接过来是设置好非阻塞标志，这样那两次<code>fcntl()</code>调用就避免了。这一改动已经合到标准库里了。</p>
<h3 id="减少重复计算优化每个函数实现">减少重复计算，优化每个函数实现</h3>
<p>GHC 有提供调优手段，不过限制不少。只有单进程程序的调优才准确。这样我们只能搞点非常规手段了。</p>
<p><code>mighty</code>考虑了这种情况。当我们配置<code>mighty</code>的 worker 数 N 在于 2 时，它会创建 N 个工作进程，父进程只用来收发控制信号。不过如果 N 为 1，则根本就不多创建进程了，初始进程就用来服务 HTTP 请求。另外如果有设置调试模式的话，<code>mighty</code>也会保持在终端运行(不变成后台进程)。</p>
<p>调优<code>mighty</code>的时候我们震惊的发现标准库里的时间格式化函数占了程序的多数时间。我们知道，HTTP 服务器是要在 Header 里返回 Date:，Last-Modified:等的：</p>
<pre><code>Date: Mon, 01 Oct 2012 07:38:50 GMT</code></pre>
<p>所以呢，我们就重实现了一下专门的 GMT 时间格式化函数。用 Haskell 的一个标准性能测试库<code>criterion</code>测试结果显示，我们的函数快不少。这样就够了么？其实在同一秒内有多个 HTTP 请求，我们需要多次格式化时间么，其实是不需要的，所以我们缓存一秒内的时间格式化结果就行了。</p>
<p>减少重复计算，优化函数实现在<a href="#实现解析器">实现解析器</a>和<a href="#composer-for-http-response-header">Composer for HTTP response header</a>上还会再讲。</p>
<h3 id="不要用锁">不要用锁</h3>
<p>不必要的锁是程序的罪恶源泉。有时候我们不知不觉就用了不少锁，比如运行时和库用了锁。要实现高性能服务器的话，我们就要找出这些锁来，尽可能地避免之。需要指出的是，锁在并行 IO manager 中更加致命。怎么找锁，怎么避免的话题放在<a href="#连接计时器">连接计时器</a>和<a href="#内存分配">内存分配</a>章节。</p>
<h3 id="使用正确的数据结构很重要">使用正确的数据结构很重要</h3>
<p>Haskell 处理字符串的标准库是 <code>String</code>，<code>String</code>不过是 Unicode 字符的链表。链表是 FP 的心脏，所以<code>String</code>还是很方便的。不过对于我们的高性能服务器来说，链表的性能远远不行，Unicode 也太复杂了，HTTP 其实是一面向字节流的协议。</p>
<p>所以，我们用<code>ByteString</code>来处理字节串(或 buffer)。<code>ByteString</code>是带元数据的字节数组。有元数据的话，我们切分字符串基本就不用拷贝字节了。下面<a href="#实现解析器">实现解析器</a>部分还会细讲。</p>
<p>关于数据结构的例子还有<code>Builder</code>和双重<code>IORef</code>。见<a href="#composer-for-http-response-header">Composer for HTTP response header</a>和<a href="#连接计时器">连接计时器</a>。</p>
<h2 id="http-request-parser">HTTP request parser</h2>
<p>除了高效的并发和多核环境下的 I/O 之外，其它方面也是要考虑的。在每个核上 Warp 也自然要都高效才行。这里最重要的就是 HTTP 的 request 解析了。它需要从 socket 中的字节流解析岀请求行和诸多 header，不过 body 就留给应用自己处理。它解析出的信息要传给应用( Yesod 应用也好，<code>mighty</code>应用也好)去构建 response.</p>
<p>处理这个请求 body 也颇考验功力。Warp 完全支持 HTTP 的流水线（pipelining)和分块(chunked)。这样 Warp 就得“组块”被分块的请求。支持流水线时，会在一个连接里传送多个请求，Warp 就必须保证应用拿到过多的数据，把下一个的 request 的一部分数据也给偷走了，也要保证不残留数据，不然下一个 request 就不知道从哪开始读数据了。</p>
<p>举个简单的例子，假设用户发了这样个请求过来：</p>
<pre><code>POST /some/path HTTP/1.1
Transfer-Encoding: chunked
Content-Type: application/x-www-form-urlencoded

0008
message=
000a
helloworld
0000

GET / HTTP/1.1</code></pre>
<p>HTTP 解析器得提取<code>/some/path</code>和<code>Content-Type</code>出来传给应用。应用开始读数据话话，Warp 还得把 chunk 头(<code>0008</code>，<code>0001</code>和<code>0000</code>)给屏蔽掉，把真正的内容(<code>message=helloworld</code>)传给应用。也不能多读，读完<code>0000</code>这个 chunk 尾巴就该收手了，不要影响下一下流水线请求(<code>GET / HTTP/1.1</code>)。</p>
<h3 id="实现解析器">实现解析器</h3>
<p>Haskell 的强大解析能力是名声在外的。传统上解析用的是组合子(combinator)来组织程序，比如<code>Parsec</code>和<code>Attoparsec</code>。<code>Parsec</code>和<code>Attoparsec</code>的文本解析模块是基于 Unicode 的，显然在 HTTP 头这种纯 ASCII 的协议解析上面毫无必要，而且开销太大了。</p>
<p><code>Attoparsec</code>其实也是提供了二进制解析接口的，避开 Unicode 开销，这已经是性能极好的库了。但是比手工裸写的解析器还是有差距的，Warp 里我们就自己手动解析。</p>
<p>这里有个小问题，我们的字节数据是怎么在内存里放的。答案是<code>ByteString</code>，<code>ByteString</code>其实由三部分组成的：指向一块内存的指针，数据开始的 offset，和数据的大小。</p>
<p>初看之下这个 offset 信息是多余的，指针的位置就可以当成是我们数据的开始位置。有这一个 offset 的好处是我们可以多个<code>ByteString</code>之间共享那一块内存的不同部分(所谓的切分，splicing)。那这些数据共享会不会引起篡改问题呢？Haskell 的所有数据结构都是不可变的，因此也就没有篡改这一说了。当没有<code>ByteString</code>引用那块内存时，它也就被回收了。</p>
<p>这种安排正合我们的意，客户端来了一个请求，Warp 分配一下比较大(目前为 4096 字节)的一个 chunk 来存放请求行和请求 header，基本上都能放下。然后 Warp 就用我们手写的解析器来解析。来看一下为什么能解析得飞快：</p>
<ol type="1">
<li><p>在内存块中我们只用查找换行符就行了，bytestring 库中的查找函数是用 C 函数中的像<code>memchr</code>来实现的，非常之快。(有些多行的 header 要复杂一些，不过原理是一样的)</p></li>
<li><p>解析过程根本不用再分配内存了，字符串切分直接指向原来的大内存块(见下图)。这里我们可以自豪一下，这里的做法比 C 语言里面的一般字符串处理还高效。C 语言里，字符串是用结尾的，切分字符串导致内存的不断分配和拷贝。</p></li>
</ol>
<figure>
<img src="https://raw.github.com/snoyberg/posa-chapter/master/bytestring.png" alt="Splicing ByteStrings" /><figcaption>Splicing ByteStrings</figcaption>
</figure>
<p>切行切完了，用相同的技术我们又在行内切 key/value 对。请求行要切得比较细。比如有一个请求行是这样的：</p>
<pre><code>GET /buenos/d%C3%ADas HTTP/1.1</code></pre>
<p>切分需要如下步骤：</p>
<ol type="1">
<li><p>分出请求的 method，path 和 version。</p></li>
<li><p>path 要用<code>/</code>给切成小块：<code>[&quot;buenos&quot;, &quot;d%C3%ADas&quot;]</code>。</p></li>
<li><p>URL decode 一下 path 的每一块 <code>[&quot;buenos&quot;, &quot;d\195\173as&quot;]</code>.</p></li>
<li><p>UTF8 decode 一下 path 的第一块，整出一下 Unicode <code>text</code> 文本：<code>[&quot;buenos&quot;, &quot;días&quot;]</code>。</p></li>
</ol>
<p>这个解析过程也很快：</p>
<ol type="1">
<li><p>和换行符切分一样，<code>/</code>查找也是飞快的。</p></li>
<li><p>URL decode 用的是打表，没有分支，每次都是一个内存寻址就行了。</p></li>
<li><p><code>text</code> 库处理 UTF-8很高效。其内存也很紧凑。</p></li>
<li><p>Haskell 还有延时示值的特性，比如你不需求用到 path，那么相应的解析代码就不会执行。</p></li>
</ol>
<p>最后还剩的就是“合块”了，这个就更简单了。解析一个 16 进制数字，再读这么多个数字的字节，最后再合在一起。这里也没有内存的拷贝。</p>
<h3 id="conduit">Conduit</h3>
<p>本文提到很多次替应用解析 request body 的事，也提到应用生成 response 传回给 server，server 再把数据组织起来发送给 socket。还有一个模块我们还没提到的是 <em>中间件</em>(middleware)。它处在应用和我们的 server 之间，能够对 request 和 response 做修改。</p>
<p>看一下<em>中间件</em>的定义吧：</p>
<pre><code>type Middleware = Application -&gt; Application</code></pre>
<p>直观的看<em>中间件</em>就是把一个应用给改造一下，预处理一下 request，修改一下 response。可能给个例子大家就很好理解了，比可一个 gzip 中间件，它呢自动的压缩应用返回的 response，并加上相应的 HTTP header。</p>
<p><em>中间件</em>需要就是修改应用的输入输出流。传统上 Haskell 对付这个问题的方法自然的 <code>lazy I/O</code>，输入输出都被抽象成一个延时求值的数据结构，处理逻辑都是在操作这个数据结构就行了。可惜的是对于一个高吞吐的服务器，lazy I/O 的问题在于其资源释放的不及时上。如比负载一高可能文件描述符释放不了用耗尽了。</p>
<p>我们可以用偏底层的抽象来直接读写数据，不过这和 Haskell 的高级抽象能力就背离了。不仅代码难以分析，一些个常见问题也不方便处理。例如，我们经常要缓冲(buffering)数据，先读进来一大块数据进来(如处理 request header)，剩下的数据交给另一个模块(web应用)去读。</p>
<p>为了解决这一矛盾，我们决定在<code>conduit</code>包上实现 WAI 协议(Warp 自然也是)。<code>conduit</code>包提供了数据流的抽象，并和 lazy I/O 很大部分是兼容的，也提供了缓冲的方法，还保证资源的立即释放。异常处理也不会混在数据处理中，被隔离到它 IO 处理中，到它该去的地方。</p>
<p>Warp 把客户端来的字节流组成一个<code>Source</code>，给客户端的字节流则组成一个<code>Sink</code>。给<code>Application</code>一个<code>Source</code>，它也返回一个<code>Source</code>。中间件能拦截 request 和 response的 <code>Source</code>，并施加修改。下图展示了中间件在应用间的关系，使用<code>conduit</code>包让程序的组合变得很简单。</p>
<figure>
<img src="https://raw.github.com/snoyberg/posa-chapter/master/middleware.png" alt="Middlewares" /><figcaption>Middlewares</figcaption>
</figure>
<p>还用 gzip 中间件的这个例子，刚开始有一个<code>Source</code>是应用的输出，它接到<code>gzip</code> <code>conduit</code>上，<code>Source</code>不断输出字节，<code>couduit</code>中的<code>zlib</code>包不断读入这些字节，然后输出压缩后的字节，又接到 Warp 或者别的中间件上。最终 Warp 把压缩后的数据通过 socket 传给客户端。在这过程中，只消耗了最少的内存，网络断开的话，剩余的压缩都不会继续。这样 CPU 和垃圾收集器的开销都已经是最小的了。</p>
<p>说起 conduit，这又是一个很大的话题，这里就不多说了，只要知道用 conduit 是 Warp 获得高性能的一个重要因素就行了。</p>
<h3 id="slowloris-攻击防护">Slowloris 攻击防护</h3>
<p>有一个问题是值得我们关注的: <a href="http://en.wikipedia.org/wiki/Slowloris">slowloris 攻击</a>。这是一种拒绝服务攻击(Denial of Service，DOS)。攻击者通过慢速发送请求，可以在同样的硬件和带宽的发起更多连接，每个连接都会消耗服务器的一定资源，不管这些连接上有没有数据在传送。当这种连接太多时，服务器的资源就会不够。因此，要是一个连接长时间不发送一定量的数据，我们得把这个连接给断了。</p>
<p>下面我们讲讲超时管理器，它是 slowloris 攻击检测中的核心。每个连接上有个计时器，每当有数据来这个计时器就被更新一下。Warp 中这是在 conduit 这一级就做好了。上面提到输入数据是一个<code>Source</code>，每当一个新数据 chunk 来了，计时器就更新一下。这个更新就是一个内存修改，所以是很快的，slowloris 检测基本对我们的性能不会有太大的反作用。</p>
<h2 id="http-response-composer">HTTP response composer</h2>
<p>这节谈谈 Warp 中的 HTTP response 组织。一个 WAI <code>Response</code> 可以有三种情况：</p>
<pre><code>ResponseFile Status ResponseHeaders FilePath (Maybe FilePart)
ResponseBuilder Status ResponseHeaders Builder
ResponseSource Status ResponseHeaders (Source (ResourceT IO) (Flush Builder))</code></pre>
<p><code>ResponseFile</code>：结果是个静态文件，<code>ResponseBuilder</code> 和 <code>ResponseSource</code>：结果是内存中动态生成的。每个结果都有<code>Status</code>和<code>ResponseHeaders</code>。<code>ResponseHeaders</code>就是 key/value header 对的一下列表。</p>
<h3 id="composer-for-http-response-header">Composer for HTTP response header</h3>
<p>以前我们用<code>Builder</code>来生成 HTTP response。首先，把<code>Status</code>和每个<code>ResponseHeaders</code>分别转成<code>Builder</code>，这些都是 O(1) 的复杂度。最后把这些<code>Builder</code>复制到最终的 buffer 中，复杂度为 O(n)。</p>
<p>说起来这<code>Builder</code>的性能应该是足够了，但对于我们的超高性能服务器来讲稍有不逮。现在我们是直接用 C 的<code>memcpy()</code>来搞。</p>
<h3 id="composer-for-http-response-body">Composer for HTTP response body</h3>
<p><code>ResponseBuilder</code>和<code>ResponseSource</code>包含的<code>Builder</code>已经是一个<code>ByteString</code>的列表了，我们把 header 的<code>ByteString</code>附到这个列表的最前面，然后<code>send()</code>它们，这过程只用一个定长比较少的内存。</p>
<p><code>ResponseFile</code>呢，Warp 用<code>send()</code>发送 header，用<code>sendfile()</code>发送 body。如果这里有缓存，<code>open()</code>，<code>stat()</code>，<code>close()</code>和其它一些系统调用都不用了可能。<code>ResponseFile</code>还有其它的一些优化细节，我们再讲讲。</p>
<h3 id="sending-header-and-body-together">Sending header and body together</h3>
<p>我们测 Warp 发送静态文件时发现，要是并发请求多的话，结果很快，但如果只有一个连接的话，Warp 其实是不快的。</p>
<p>用<code>tcpdump</code>来观测发现，Warp 用<code>writev()</code>来发送 header，用<code>sendfile()</code>来发送 body。header 和 body 是走两个 TCP 包。</p>
<figure>
<img src="https://raw.github.com/snoyberg/posa-chapter/master/tcpdump.png" alt="Packet sequence of old Warp" /><figcaption>Packet sequence of old Warp</figcaption>
</figure>
<p>为了能够在一个 TCP 包中就发送完，我们改了一下 Warp，把<code>writev()</code>调用改成<code>send()</code>，在<code>send()</code>加上<code>MSG_MORE</code>标志位，然后接上一个<code>sendfile()</code>，header 和 body 就在一个 TCP 包里就发送了。提高了 100 倍的性能。</p>
<h2 id="超时和清理">超时和清理</h2>
<p>这节阐述连接超和缓存文件描述符。</p>
<h3 id="连接计时器">连接计时器</h3>
<p>为了防备 slowloris 攻击，用户长时间不多发点数据连接就被掐断了。Haskell 有个库函数叫<code>timeout</code>：</p>
<pre><code>timeout :: Int -&gt; IO a -&gt; IO (Maybe a)</code></pre>
<p>第一个参数是超时毫秒数，第二个参数是一个 IO 操作。<code>timeout</code>函数返回一个 IO 类型的 <code>Maybe a</code>。<code>Maybe</code> 又是啥：</p>
<pre><code>data Maybe a = Nothing | Just a</code></pre>
<p><code>Nothing</code> 说明有错误(不过没说原因)，<code>Just</code>则是一个成功的结果<code>a</code>。所以 IO 操作没有在指定时间完成的话，<code>timeout</code>函数返回一个<code>Nothing</code>，反之则返回一个包在<code>Just</code>中的结果。这里也可以看出 Haskell 描述的方式多么流畅。</p>
<p><code>timeout</code>对大多数人来说足够了，对于我们的高性能服务器来说，又不够。原因呢，<code>timeout</code>函数会起一个用户态线程，虽然上面我们说用户态线程很轻量，可是也还是有开销的，尤其调用太多次的话。我们要把这个超时处理中的用户态线程的创建给优化掉。做法是把超时统一给一个用户态线程管理。看一下要点：</p>
<ul>
<li>双重 <code>IORef</code></li>
<li>安全交换与合并算法</li>
</ul>
<p>假设每个连接的状态要么是<code>Active</code>，要么是<code>Inactive</code>。超时管理器不断的检查每个连接的状态，如果是<code>Active</code>，超时管理器就把它标记成<code>Inactive</code>，超时管理器就把相应的用户态处理线程给杀了。</p>
<p>每个状态是们保存在<code>IORef</code>里的。<code>IORef</code>是个引用，里面的数据是可以修改的(译注：和别的 Haskell 数据结构不同)。每个用户线程要不断的更新其状态为<code>Active</code>，不然就被杀了。</p>
<p>超时管理器用一下<code>IORef</code>的列表保存这个状态。每创建一个用户态线程，也要创建一下相应的<code>IORef</code>放到该列表中，状态为<code>Active</code>。这个列表是个关键的数据结构，对它要进行原子以保证一致性。</p>
<figure>
<img src="https://raw.github.com/snoyberg/posa-chapter/master/timeout.png" alt="A list of status. A and I indicates Active and Inactive, respectively" /><figcaption>A list of status. <code>A</code> and <code>I</code> indicates <code>Active</code> and <code>Inactive</code>, respectively</figcaption>
</figure>
<p>一般 Haskell 用<code>MVar</code>来保证一致性，但是<code>MVar</code>用锁来保证一致性，太慢了。我们只好用<code>IORef</code>，并用<code>atomicModifyIORef</code>操作来保证一致性。<code>atomicModifyIORef</code> 是用 CAS(Compare-and-Swap)来实现的，比锁要快。</p>
<p>下面是我们交换和合并算法的一个大概：</p>
<pre><code>do xs &lt;- atomicModifyIORef ref (\ys -&gt; ([], ys)) -- swap with an empty list, []
   xs&#39; &lt;- manipulates_status xs
   atomicModifyIORef ref (\ys -&gt; (merge xs&#39; ys, ()))</code></pre>
<p>超时管理器先用一个空表把列表换出来，然后修改列表的状态，杀死<code>Inactive</code>的线程。此时并不影响新线程的加入(译注：加入到原来的空表中)，它们可以用<code>atomicMonifyIORef</code>加入状态。最后超时管理器又原子地把两部分列表合并起来。Haskell 是延时求值的，这样这次合并操作是 O(1) 就返回了，实际的 O(n) 合并只有在下次读这个列表时才真正进行。</p>
<h3 id="文件描述符计时器">文件描述符计时器</h3>
<p>考虑这种情况：Warp 需要用<code>sendfile()</code>发送一整个文件。不幸的是，Linux 平台下，先得调<code>stat()</code>函数得到文件大小，传给<code>sendfile</code>(FreeBSD/MacOS 可以用一个 magic number <em>0</em> 表示整个文件)。</p>
<p>如果 WAI 应用事先知道文件大小，Warp 就不用调<code>stat()</code>了。缓存这个文件大小很容易，要注意的是内存中的大小可能会和实际不一致(修改过的话)。不过这个并不是个大问题，比如我们设置一个 10 秒种的缓存超时时间就没啥问题了。10 秒后缓存会被清理，不会泄漏。</p>
<p><code>sendfile</code>要用文件描述符，调用<code>open()</code>，多次调用<code>sendfile()</code>，再<code>close()</code>是可以的。接下来，我们来讨论一下怎么缓存文件描述符，避免重复调用<code>open()</code>和<code>close()</code>。缓存的过程是这样的：先用<code>open()</code>打开一个文件描述符，后来如果别的线程也要用这个文件的话就直接能重用，过了一段时间没人用就可以把它关闭了。</p>
<p>有个简单的策略是引用计数，但我们不确定能不能实现一下健壮的引用计数器。如果用户线程发生异常，没有及时减掉引用计数器怎么办？文件描述符就泄漏了。我们发现连接超时管理器上的机制也能用在这里，也不需要引用计数器，不过重用也没这么简单就是。</p>
<p>每个线程有个自己的状态，状态是不共享的，文件描述符是需要共享的。所以得有个办法能快速查找某文件的对应描述符，列表是不能用了，太慢。一个文件可能同时被打开多次，我们就用了一个 <em>multimap</em> 来存文件对应的描述符。</p>
<p>我们的 multimap 是查找时间复杂度为 O(log N)，修改的复杂度为 O(N) 的红黑树。红黑树是二分查找娄，查找时间自然就是 O(log N)，N 为节点数。把树变成个有序列表则要 O(N)。修改文件描述符用这样变换实现的。</p>
<h2 id="未来展望">未来展望</h2>
<p>对于如何进一步优化 Warp，我们有许多想法，这里拿两个来讲一下。</p>
<h3 id="内存分配">内存分配</h3>
<p>每次收发数据包，都需要分配内存 buffer。这些 buffer 以<em>钉住</em>(pinned)的形式分配，这样这些 buffer 可以在 C 和 Haskell 之间共享。我们希望每次系统调用收发的数据能多一点，这些 buffer 一般会是中等大小的。不幸的是，GHC 分配稍大一点(64 位机上是大于 409 字节)的钉住内存会用到运行时的一个锁。当内存频繁分配时，这在机器超过 16 核时就成为了我们的系统环境。</p>
<p>我们开始分析 HTTP response header 生成时，这种针住大内存的分配对性能的影响。GHC 对我们的提供了 <em>eventlog</em> 工具，它能记录每个事件的时间戳。在内存分配的前后我们挂上函数记录用户事件的时间，然后和<code>mighty</code>编译在一起，得到的事件日志(event log)结果如下：</p>
<figure>
<img src="https://raw.github.com/snoyberg/posa-chapter/master/eventlog.png" alt="eventlog" /><figcaption>eventlog</figcaption>
</figure>
<p>小红块就是我们挂上的事件，它们之间的时间自然就是内存分配的时间了。粗略估计大概占到 HTTP 会话中的 1/10。怎么实现一下无锁的内存分配算法，还在讨论中。</p>
<h3 id="新式惊群">新式惊群</h3>
<p>惊群(Thundering herd)是一下历久弥新的问题。</p>
<p>假设多个进程或系统线程预创建着监听同一个 socket。他们都在这个 socket 上<code>accept()</code>。一个连接进来，老版本的 Linux 和 FreeBSD 会唤醒所有这些进程，但只有一个进程拿到这个连接，其它进程接着 sleep。这样的上下文切换是个严重的性能问题。这就是所谓的<em>惊</em> <em>群</em>。较新版本的 Linux 和 FreeBSD 只唤醒一个进程，所以这个问题已经成为历史了。</p>
<p>不过呢，新的网络服务器又开始用<code>epoll</code>系列函数。如果多 worker 共享一个 socket，用<code>epoll</code>系函数操作这个 socket，惊群问题又回到了我们眼前。这是因为<code>epoll</code>系函数会通知(唤醒)所有进程。<code>nginx</code>和<code>mighty</code>都是这种新式惊群的受害者。</p>
<p>如果用了并行的 IO manager 的话，这种新式惊群就没有了。在新的架构下，只有一个 IO manager 用<code>epoll</code>监听 socket，再将建立好的连接交给其它 IO manager 处理。</p>
<h2 id="结论">结论</h2>
<p>Warp 是一个面面倶到的网络服务器库。为各种用途都提供了高效的 HTTP 通信方案。为了取得目前的高效，它在诸多级别上都做了大量的优化工作，如网络通信层，线程管理层，请求解析层。</p>
<p>Haskell 也被证明是写这种代码的惊艳的语言。默认数据只读等特性也让编写线程安全，少数据复制的代码成为可能。</p>
<p>多线程的运行时库使得写事件驱动的代码很简单。GHC 的强大优化能力也意味着我们可以写高阶抽象的代码，又能收获极致的性能。我们的性能如此之高，代码量却相对不多(写这篇文章时有 1300 行代码)。如果你有志于写可维护，高性能，并行化的代码，Haskell 绝对你是不该错过的。</p>]]></summary>
</entry>
<entry>
    <title>Postgres 中的简单压缩算法</title>
    <link href="http://veryr.com/posts/simple_lz_compress/" />
    <id>http://veryr.com/posts/simple_lz_compress/</id>
    <published>2013-11-27T00:00:00Z</published>
    <updated>2013-11-27T00:00:00Z</updated>
    <summary type="html"><![CDATA[<p>Postgres 的页面(page)大小是固定的 8k，同一行的数据必须在同一个页面内，但是 Postgres 需要支持变长的数据类型(如 varchar)，是可能超过 8k 的。解决方案是所谓的 <a href="http://www.postgresql.org/docs/current/static/storage-toast.html">TOAST</a> (The Oversized-Attribute Storage Technique, 过长字段存储技术)。</p>
<p>TOAST 解决的思路一个是压缩，一个是页外存储。两个可以结合：页外压缩存储。页外存储就是在每个有变长字段表的 table 存储文件外再创建一个 .toast 结尾文件，过长字段存放在 .toast 文件，并将 offset 放在原 table 文件中替代。这样还能提高扫表的速度(如果此次查询不需要这个字段的话)。</p>
<p>Postgres 的压缩采用的是一个极简单的 lz 字典压缩算法。从解压过程来理解其原理的话非常简单：</p>
<pre><code>sp= 11110000 | 0x41 | 0x42 | 0x43 | 0x44 | 0x01 | 0x00 | 0x05 | 0x00 | 0x0d | 0x00 | 0x0f | 0x00  | 0x0e  |
    ———————————————————————————————————————————————————————————————————————————————————————————————————————
    control  | data | data | data | data | len4 + off12| len4 + off12| len4 + off12| len4 + off12 | len8  |
    ———————————————————————————————————————————————————————————————————————————————————————————————————————
             | &#39;A&#39;  | &#39;B&#39;  | &#39;C&#39;  | &#39;D&#39;  | len:4 off:0 | len:8 off:0 | len:16 off:0| len:18 off:0 | len:14|
    ____________|      |      |      |         |             |             |              |              |
    |__________________|      |      |         |             |             |              |       +      |
    ||________________________|      |         |             |             |              |———————————————
    |||______________________________|         |             |             |              |
    ||||  _____________________________________|             |             |              |
    ||||  |     _____________________________________________|             |              |
    ||||  |     |          ________________________________________________|              |
    ||||  |     |          |                       _______________________________________|
    ||||  |     |          |                       |
    ||||{4-}{---8--}{------16------}{--------------32--------------}
dp= ABCDABCDABCDABCDABCDABCDABCDABCDABCDABCDABCDABCDABCDABCDABCDABCD</code></pre>
<p>sp = [oxf0,0x41,0x42,0x43,0x44,0x01,0x00,0x05,0x00,0x0d,0x00,0x0f,0x00,0x0e] 这样的一个压缩串能解压成什么呢？首先，先读一个 control byte，在这个例子里面就是 0xf0，也就是二进制的 11110000。从最低位开始看：</p>
<ul>
<li>每看到一个 0 bit，就将 sp 的下一个字节原样写到结果 dp 里。</li>
<li>每看到一个 1 bit，就再读两个字节 byte1 和 byte2, len = [byte1 的低4位] + 3，off = [byte1 的高4位] * 256 + [byte2]。如果 len == 18, 那么再读一个字节 byte3，len += byte3。然后从 dp 的末尾往前 off 个字节拷贝 len 个字节到 dp 里。</li>
</ul>
<p>这样我们一个长度为14字节的 sp 解压成一个 长度为64字节的dp，压缩比为14/64 ~= 22%。代码在 postgres/src/backend/utils/adt/pg_lzcompress.c 。简单利落得令人发指。</p>
<pre lang="c"><code>void pglz_decompress(const PGLZ_Header *source, char *dest) {
	const unsigned char *sp;
	const unsigned char *srcend;
	unsigned char *dp;
	unsigned char *destend;
	sp = ((const unsigned char *) source) + sizeof(PGLZ_Header);
	srcend = ((const unsigned char *) source) + VARSIZE(source);
	dp = (unsigned char *) dest;
	destend = dp + source-&gt;rawsize;
	while (sp &lt; srcend &amp;&amp; dp &lt; destend) {
		unsigned char ctrl = *sp++;
		int			ctrlc;
		for (ctrlc = 0; ctrlc &lt; 8 &amp;&amp; sp &lt; srcend; ctrlc++) {
			if (ctrl &amp; 1)
			{
				int32		len;
				int32		off;

				len = (sp[0] &amp; 0x0f) + 3;
				off = ((sp[0] &amp; 0xf0) &lt;&lt; 4) | sp[1];
				sp += 2;
				if (len == 18)
					len += *sp++;
				if (dp + len &gt; destend) {
					dp += len;
					break;
				}
				while (len--) {
					*dp = dp[-off];
					dp++;
				}
			}
			else {
				if (dp &gt;= destend)		/* check for buffer overrun */
					break;				/* do not clobber memory */

				*dp++ = *sp++;
			}
			ctrl &gt;&gt;= 1; 				/* Advance the control bit */
		}
	}
}
</code></pre>
<p>再来看压缩过程，压缩比解压复杂，就好比给车打气比放气难，又好比吃饭比做饭容易，又好比考公务员比下海难。代码的实现比较复杂，但是原理还是比较直观的。</p>
<p>给定一个待压缩串 source，压缩的结果输出到 dest。数据还是用上面的例子，只是过程反过来。</p>
<ul>
<li>如果 control byte 没有分配或已经用完的话，在 dest 里分配一个 control byte</li>
<li>取 source 串的下一个待压缩序列长度至少为 3 的尽量长的序列</li>
<li>如果在已压缩的 source 串中能找到一个连续的串和待压缩串相同，那么 control bit 置 1，并将 source 串中的 offset 和 len 写入 dest。</li>
<li>如果没有找到，那么将 control bit 置 0，将 source 中的下一个字节直接写入 dest。</li>
</ul>
<p>如此重复，直到压缩完成 source 串中的所有字节为止。具体代码可以参看 pglz_decompress.c 文件。</p>]]></summary>
</entry>
<entry>
    <title>Postgres 的文件存储位置</title>
    <link href="http://veryr.com/posts/postgres-storage-location/" />
    <id>http://veryr.com/posts/postgres-storage-location/</id>
    <published>2013-11-21T00:00:00Z</published>
    <updated>2013-11-21T00:00:00Z</updated>
    <summary type="html"><![CDATA[<p>initdb 的时候会指定一个 PGDATA 目录，这就是 PostgresQL 存储数据的地方。典型的位置是在 /var/lib/postgres/data 或 /home/postgres/data 。PGDATA 下面各项存储的内容大概是：</p>
<table>
<thead>
<tr class="header">
<th style="text-align: left;">文件或目录名</th>
<th style="text-align: left;">存储内容</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">PG_VERSION</td>
<td style="text-align: left;">PostgresQL 实例的版本号如 9.3 之类的</td>
</tr>
<tr class="even">
<td style="text-align: left;">base</td>
<td style="text-align: left;">每个 database 会在 base 目录下有一个子目录</td>
</tr>
<tr class="odd">
<td style="text-align: left;">global</td>
<td style="text-align: left;">Postgres 自己的 meta 数据库存放的地方（全局 DB）</td>
</tr>
<tr class="even">
<td style="text-align: left;">pg_xlog</td>
<td style="text-align: left;">WAL(Write Ahead Log 预写式日志）存放的地方</td>
</tr>
<tr class="odd">
<td style="text-align: left;">其他</td>
<td style="text-align: left;">其他不知道干啥的目录还有好多</td>
</tr>
</tbody>
</table>
<p>base 目录是最重要的一个目录，放的是每一个 database 的数据。base 目录里的每一个数字目录对于一个 database 的 oid， 可以通过 查看 pg_database 这张表查看每一个 数据库的 oid 。</p>
<pre><code>lai=# select oid, datname from pg_database ;
  oid  |  datname  
-------+-----------
     1 | template1
 12031 | template0
 12036 | postgres
 16385 | lai
(4 rows)</code></pre>
<p>每一张表的数据（大部分）又是放在 base/(dboid)/(relfilenode) 这个文件里面：</p>
<pre><code>lai=# select relname, relowner, relfilenode from pg_class where relowner = 16384;
        relname        | relowner | relfilenode 
-----------------------+----------+-------------
 pg_toast_24589        |    16384 |       24592
 pg_toast_24589_index  |    16384 |       24594
 pg_toast_24595        |    16384 |       24598
 pg_toast_24595_index  |    16384 |       24600
 item_id_seq           |    16384 |       24601
 Feed_pkey             |    16384 |      167963
 feed                  |    16384 |       24589
 item                  |    16384 |       24595
 pg_toast_168003       |    16384 |      168006
 pg_toast_168003_index |    16384 |      168008
 tmp                   |    16384 |      168003
(11 rows)</code></pre>
<p>feed 这张表数据在 base/16386/24589 文件里，item 这张表的数据放在 base/16386/24595 这个文件里。也可以用 pg_relation_filepath 这个函数查询：</p>
<pre><code>lai=# select pg_relation_filepath(&#39;item&#39;);
 pg_relation_filepath 
----------------------
 base/16385/24595
(1 row)</code></pre>
<p>当然实际的存储不会这么简单。每一张表的文件都会有一些附加的存储文件，如文件名后加上 _fsm 的是空闲空间映射表 (Free Space Map)。另外 base/(dboid)/(relfilenode) 这个文件超过 1GB 以后，Postgres 会把这个文件拆分成不超过 1G 的多个文件，文件末尾加上 .1 .2 .3 … 做编号。 如 24589 24589.1 24589.2 。据说这是因为某些文件系统支持的最大文件大小有限制(如 fat32 只支持最大 4G )的文件。</p>]]></summary>
</entry>
<entry>
    <title>论如何才能拿到一个博士学位</title>
    <link href="http://veryr.com/posts/you-need-to-get-phd/" />
    <id>http://veryr.com/posts/you-need-to-get-phd/</id>
    <published>2013-11-14T00:00:00Z</published>
    <updated>2013-11-14T00:00:00Z</updated>
    <summary type="html"><![CDATA[<p>王同学上周又有高论，把 OOP 和 FP 都喷了一遍。文章被人贴到 <a href="https://news.ycombinator.com/item?id=6716399">HN</a> 和 <a href="http://www.reddit.com/r/programming/comments/1qg5x8/whats_wrong_with_oop_and_fp/">Reddit</a> 上，被几个明白人扔了两板砖。立马就把文章给改了，标题都从 Whats wrong with Object-Oriented Programming and Functional Programming 这种还有点意思的改成 <a href="https://yinwang0.wordpress.com/2013/11/09/oop-fp/">Pure OOP and Pure FP</a>，还顺手吧评论删了，关了。我说王同学这就没意思了。你之前说 OOP 和 FP 是两砣那啥，虽然逻辑不行，至少还能让大家讨论讨论，引玉出来，你现在的这打这哈哈说 OOP 和 FP 有未必好，没有未必不好，该用的时候用，不该用的时候不要滥用，你说这和没说有甚么分别？</p>
<p>OOP 咱不了解，话说 FP 的话王同学的高论不过就是说物理世界是有状态的，有副作用的，所以用无状态的，纯函数的 FP 来写代码处理是不行的。王同学怎么说也是念过博士的人是吧，咋还一点基本的科学素养也没有。世界是有状态的？这话物理学家也未必这么利器在手，自信满满可以这么说吧？退一步讲世界是 stateful 的又如何，难道不能用纯函数去描述？假如物质是量子的、离散的，我们就不能用连续的数学函数去描述物体的运动？</p>
<p>经济学里也有个规范分析和实证分析的区别，实证分析研究“是什么”，规范分析研究“该怎样”。某地发生地震了，根据供需关系物价会上涨，这在描述一个事实，是实证分析。在地震的地区该不该管理坐地起价的行为，分别有什么利弊，这个是规范分析。两个都能弄错，也是国人的常态，大概也是出国了也拿不到博士学位的原因。</p>]]></summary>
</entry>
<entry>
    <title>为什么我觉得 360 搜索能成功</title>
    <link href="http://veryr.com/posts/360-search/" />
    <id>http://veryr.com/posts/360-search/</id>
    <published>2013-03-03T00:00:00Z</published>
    <updated>2013-03-03T00:00:00Z</updated>
    <summary type="html"><![CDATA[<h2 id="百度">百度</h2>
<p>先看看为什么百度能打败 Google.</p>
<ol type="1">
<li>Google 和政府关系不好, 在05, 06年中国人的搜索习惯的开始形成的关键时间点上不间断的被 GFW reset 连接.</li>
<li>Baidu 线下工作做得好, 派人挨个网吧给点钱让把首页设成 Baidu. 积级联系代理商拉客户. 这是 Google 不会做, 不屑于做的 “不酷”的事, Baidu 做好了.</li>
</ol>
<p>可以说是流氓打败了贵族, 也可以说是务实打败了清高.</p>
<h2 id="搜索格局为什么难有大变动">搜索格局为什么难有大变动</h2>
<p>这几年不论国内国外, 搜索的格局一直没怎么变. 即使是微软这个财主, 对Bing的持续投入已达数十亿美元, 却依然撬不动 Google 的一点份额. 腾讯 soso 数十亿的投入也如打水漂了. 为什么说 360 就能成事呢?</p>
<p>搜索的技术壁垒基本上没有了, 连盘古, 即刻这些个国家队上场的时候更加说明了这一点. 问题在两边: 用户和客户.</p>
<ul>
<li>用户这边</li>
</ul>
<p>由于上文说的搜索的技术壁垒基本没有, 结果说就是大家的搜索质量最差不太远, 也就是多索引了些和少索引了些的区别, 因为用户需要的内容一般都在前几页, 所以没什么影响. 那怎么拉用户? 一是用户习惯, 这个不说了; 二是软件预装, 这说是巨头都做浏览器的原因, Google 的浏览器做得好, 微软的做的不好, 所以微软的搜索份额上不去. 腾讯的浏览器做得了不好, 所以搜索上不去, 搜狗的浏览器做得好, 搜索的份额就抢到一点. 360也是. Baidu 浏览器没啥份额, 但是人捆绑插件做得好(:D).</p>
<ul>
<li>客户这边</li>
</ul>
<p>有了流量怎么变现? 这个各家技术就有区分度了. Facebook 的一名早期员工 Hammerbacher 曾说过这么一句话: &gt; 我这代人中最聪明的大脑都在思索如何让人们点击广告，很操蛋。</p>
<p>Google 靠的是机器学习, 通过海量的数据挖掘来, 通过用户的搜索习惯来找到用户的兴趣, 把用户再卖给客户. 这个精确程度能决定你变现的能力. 而且是数据量越大, 挖掘越精准, 变现越容易. 所以 Google 和 Baidu 在这方面的优势只会越来越大.</p>
<p>用户那边其实不重要, 客户这边没变现才很致命. 无收入意味得撑不久, 所以 soso 撤了.</p>
<h2 id="为什么说-360-能够成功">为什么说 360 能够成功</h2>
<p>那就是比百度更加流氓, 更加务实.</p>
<ol type="1">
<li>拉用户无所不用, “安全卫士” 捆绑 “安全浏览器”, “安全浏览器” 捆绑 “安全搜索”, 圆环套圆环, 一条龙服务.</li>
<li>别人不敢用的变现手段. 这才是 360 的杀手锏.</li>
</ol>
<p>我现在也在做广告投放, 海量数据的机器挖掘有个很大的弱点: 无法精确定位一个人. 传统的 Cookie, Flash Cookie, 随着用户改用浏览器, 重装系统, 换新电脑, Ghost 还原就失效了. 给机器挖掘带来很大的杂音, 除在挖掘信息之前需要把不同的 Cookie 合并成一个人, 这个合并是不准确的, 再加上机器挖掘本身就不是很准确, 这样偏差就很大了, 处理起来很困难.</p>
<p>Google 的办法是用 Gmail, Google Reader, Gtalk, Google+, Google Docs 等免费好用的服务让你用, 让你自愿的将自己的搜索数据送给 Google. Baidu 这方面就做得不好, 一直没有像 Google 一样有一个 Gmail ID 打通自己的产品线, 用一个 Google ID 将一个人的行为统一收集起来.</p>
<p>360 的办法就更牛了, 通过客户端直接收集用户的行为: 不管你注册不注册 360 账号, 360 都可以把你的所有行为关联起来, 只要你用了 360 “安全浏览器”, 360 “安全卫士”, 360 “安全搜索”. 这样省去了把不同的 Cookie 合并成一个人这一高难度, 吃力做不好的事情, 精确定位到人, 精准投放广告, 变现能力变得比 Google 还强了.</p>
<p>所以说收集用户隐私是 360 的基因, 所以每日经济新闻发表了一篇<a href="http://epaper.nbd.com.cn/shtml/mrjjxw/20130226/118530.shtml">《360 黑匣子之谜——奇虎360“癌”性基因大揭秘》</a>, 才会让周红衣暴跳如雷, <a href="http://tech.163.com/13/0228/16/8OQK8N7T000915BF.html">起诉《每日经济新闻》</a>, 因为这简直要了 360 的命根子. 这就是为什么 360 在媒体的天天曝光下还要收集用户资料, 这就是 2012 年 <a href="http://news.163.com/12/0206/18/7PJM5MMR00014JB5.html">360产品被苹果应用商店全部下架</a>, 之后还不改, 今年又发生了除 360 云盘外的 <a href="http://www.techweb.com.cn/internet/2013-01-26/1273042.shtml">360 全部应用被苹果 从 App Store 下架</a>.</p>
<p>有人可能会说 Google 也是收集用户隐私, 360 也是收集用户隐私, 用户隐私难道是庙里的尼姑, Google 动得, 我 360 动不得. 这有个区别, Google 收集的只是你搜索和点击和浏览的记录, 而且还提供了工具给你<a href="https://www.google.com/settings/exportdata">查看下载</a>, 让你<a href="https://www.google.com/history/edit?authuser=0">删除</a>. 而且你是自愿给 Google 送过去的, 像很多人知道 Google 在收集信息, 也懒得在每次搜索前退出 Google 帐号. 360 则还收集你硬盘上的数据, 你使用电脑的记录, 还不承认它收集了, 更不要说提供给你查看, 删除的入口.</p>
<p>收集用户隐私违法吗, 这个不好界定, 现在也没有太完善的法律. 在美国去年<a href="http://www.guao.hk/posts/google-agrees-to-pay-hefty-22-5m-fine-in-safari-bypass-dispute.html">Google 就绕过 Safari 隐私控制的行为收集用户隐私被处 2250 万美元的罚款</a>. 美国人的隐私, 欧洲人的隐私是比较金贵的, 所以微软的 <a href="http://bing.com">Bing</a> 不会有前途. 中国人的隐私, 呵呵. 所以说 360 说 <a href="http://mobile.163.com/13/0227/22/8OOM5NRO0011665S.html">360 搜索 2015 年份额超 40%</a>. 我觉得是可能的, 40% 没有, 30% 总是有的.</p>
<h2 id="百度会坐以待毙吗">百度会坐以待毙吗</h2>
<p>简单来说答案是会的.</p>
<p>周红衣 做 “免费” 的安全卫士, 杀毒软件, 安全浏览器, 目的不是做活雷锋, 目的就是做搜索, 多年以前的他就只这么盘算的, 只是现在到了他收割的时候了. 你不让他收割能答应吗? 百度家大业大, 这种盗取用户隐私的事一是没能力做(Baidu 没有做客户端的基因), 二是不敢做, 这种会把自己置于风口浪尖的事风险太大(躺着也能竞价排名, 做这么高危的事情做什么?), 搞不好被竞争对手死命宣传, 偷鸡不成蚀把米就惨了. 360 不一样, Nothing to lose, 不做不能变现(参考 Sougou, Bing, Soso), 白做了这么久的雷锋, 做了争议大, 但是很大的可能能变现. 你会选择那样?</p>]]></summary>
</entry>
<entry>
    <title>企业级市场</title>
    <link href="http://veryr.com/posts/enterprise-market/" />
    <id>http://veryr.com/posts/enterprise-market/</id>
    <published>2013-02-20T00:00:00Z</published>
    <updated>2013-02-20T00:00:00Z</updated>
    <summary type="html"><![CDATA[<h2 id="企业级市场">企业级市场</h2>
<p>黑莓给人的印象一直是专注于“企业级市场”，近些年在消费市场上节节败退。 与黑莓类似的还的一家公司：微软。微软的 Window Phone 8 发布好久了， Surface RT， Surface Pro 也上市了。但是反响貌似也不是很好，市场占有率一直上不去。这两家公司号称在企业级市场上有独到的优势，它们的消费电子市场上一塌糊涂还情有可原，可是现在他们在企业市场上也被 Google，苹果打得满地找牙，是什么原因呢？</p>
<h2 id="到底什么是企业级市场">到底什么是企业级市场</h2>
<p>我浅陋，也不太知道企业级市场是个什么东东。大概估计就是个企业采购的市场。我觉得下面的几个东西的大概就是企业级市场应用了：IBM Lotus， IE 6， 公司服务器上的 RHEL 5。 这些玩意有什么共同特征呢？</p>
<ol type="1">
<li>版本老，旧，基本上是10年前开发的，N久没更新了</li>
<li>难用，不想用</li>
<li>但是必需要用</li>
</ol>
<p>那我就明白了，到底什么是企业级市场。往好里说是追求稳定和安全在第一位的市场。一般采用了一个应用以后，会用很长一段时间，替换的成本很大。比如我们服务器上的 Centos 5.5, GCC 4.1.2，7，8年了也不能更新，安装个啥新软件都很费劲，安装一个 GHC 7.6 费了我一天多的时间。说得难听点就是绑架住用户，一旦用了以后要一直用，一直收钱，收钱还贼贵。</p>
<p>这个东西你偷偷做就行了，骗人骗久了，垄断的钱赚的太容易，自己智商也下降了，以为这真的是一个真正存在的“企业级市场”，还把这做为贵司的一个优势来宣传，真真让人笑掉大牙。微软花了天价的广告费宣传 Windows Phone，但是其销售没点起色，不是没有原因的。</p>
<p>差点忘了，还有一家企业在消费市场上不得意，也转向“企业级市场”。这是惠普，把刚买一年的Webos给废了，让无数Palm粉丝心灰意冷。怎么进军这个企业级市场呢？收购Autonomy，不曾想遭Autonomy财务欺诈亏损88亿美元，真是不好好做产品，想去“企业级市场”骗钱，反倒被骗子给骗了，真是活该。</p>
<p>根本就没有什么所谓的企业级市场，企业到底也是由人构成的，企业购买产品到底也是人用的。产品做的不好，想着绑架企业，迟早是要被抛弃的。像苹果没有特地去经营什么企业级市场，被企业内的人自下而上的推动，反而在企业级的销售情况变得越来越好。</p>]]></summary>
</entry>
<entry>
    <title>纯洁的 IO 与 自由的 Monad</title>
    <link href="http://veryr.com/posts/io-and-monad/" />
    <id>http://veryr.com/posts/io-and-monad/</id>
    <published>2012-08-29T00:00:00Z</published>
    <updated>2012-08-29T00:00:00Z</updated>
    <summary type="html"><![CDATA[<h2 id="myths-and-legends">Myths and Legends</h2>
<p>Haskell 里 IO 操作也是纯函数，这多多少少会让初学者感情上难以接受。前几年 TopLanguage 就有几个哥们为 IO 是不是纯的争得面红耳赤，不欢而散。</p>
<p>在 Haskell 里面 IO 操作时是用 Monad 来建模的，一般的 IO 教程上会使用这样的模型来帮助理解：</p>
<pre><code>data IO a = IO (RealWorld -&gt; (RealWorld, a))</code></pre>
<p>这个模型的好处是易于理解。</p>
<h2 id="实现-io-monad">实现 IO Monad</h2>
<p>真正要理解一个概念，最好的办法就是实现它。在实现它的时候，为啥这个概念要这么设计，很多取舍你才会更深刻的理解它。</p>
<p>下面我们自己来实现一个 IO 库好了。</p>
<p>首先是 import, 先用 NoImplicitPrelude 防止自动引入 Prelude 里面预定义的 IO(我们要自己实现).</p>
<pre lang="haskell"><code>
{-# LANGUAGE DeriveFunctor, NoImplicitPrelude #-}
import Data.Function
import Data.Functor
import Data.String
import Control.Monad
import Prelude(Show(..), (++))
import qualified System.IO
import qualified System.Exit
</code></pre>
<p>定义三个基本的 IO 操作: GetLine, PutStr, Stop.</p>
<pre><code>data BasicIO next = GetLine (String -&gt; next) | PutStr String next | Stop
    deriving (Functor)</code></pre>
<p>定义一个 Helper 函数：</p>
<pre><code>class FunctorTrans t where
    liftF :: Functor f =&gt; f a -&gt; t f a

instance FunctorTrans Free where
    liftF = Free . fmap Pure</code></pre>
<p>定义三个 IO 函数: putStr, getLine, exit: 这是我们最经常用(如果不是唯一用的)的三个 IO 函数.</p>
<pre><code>putStr :: String -&gt; IO ()
putStr s = liftF $ PutStr s ()

getLine :: IO String
getLine = liftF $ GetLine id

exit :: IO a
exit = liftF Stop</code></pre>
<p>print 和 putStrLn 也是常用的， 当然需要定义一下:</p>
<pre><code>putStrLn :: String -&gt; IO ()
putStrLn = putStr . (++ &quot;\n&quot;)

print :: Show a =&gt; a -&gt; IO ()
print = putStrLn . show</code></pre>
<p>那上面的 IO 又是什么呢？ 下面我们就来定义一下：</p>
<pre><code>data Free f a = Pure a | Free (f (Free f a)) deriving (Functor)
type IO = Free BasicIO</code></pre>
<p>IO 是一个 Monad, 我们当然要实现：</p>
<pre><code>instance Functor f =&gt; Monad (Free f) where
    return = Pure
    Pure a &gt;&gt;= f = f a
    (Free x) &gt;&gt;= f = Free $ fmap (&gt;&gt;= f) x</code></pre>
<p>现在这个 IO 就可用了，不信的话，下面用上面定义的 IO 来写一段代码吧：</p>
<pre><code>freeMain = do
    x &lt;- getLine
    y &lt;- getLine
    putStrLn $ x ++ y
    exit
    putStrLn $ x ++ y</code></pre>
<p>到此为止，我们定义的 IO， 就算写完了。 这个 IO 是纯洁的吗？是。至少上面我们用到的都是纯函数。</p>
<p>那 IO Monad 真的是纯的吗？ 下面把我们自己当做 Haskell 的运行时。看一下 IO Monad 到底是怎么运行的：</p>
<pre><code>runIO :: IO a -&gt; System.IO.IO a
runIO (Pure a) = return a
runIO (Free (GetLine f)) = System.IO.getLine &gt;&gt;= runIO . f
runIO (Free (PutStr s next)) = System.IO.putStr s &gt;&gt; runIO next
runIO (Free Stop) = System.Exit.exitSuccess</code></pre>
<p>给个 main 函数运行一下：</p>
<pre><code>main = runIO freeMain</code></pre>
<h2 id="小结">小结</h2>
<p>Monad 是纯洁的吗？ 虽然在 IO Monad 执行的时候会用到不纯的 Syste.IO 里面的函数, 我们应该还是应该把 IO Monad 看成纯函数。 不能因为 runIO 的不纯就说 IO Monad 不纯。这件事我们应该从语义上去看，不应该从实现的手段去看。 比如我们用 C 语言写一个 Haskell 的解释器，C 语言里面都是副作用，那么在这个解释器里运行的 Haskell 代码是不纯的吗？</p>
<h2 id="从控制反转的角度来看-io-monad">从控制反转的角度来看 IO Monad</h2>
<p>上面的代码, 虽然用在 Haskell 中用纯函数实现了一个 IO Monad。但是还是不太直观。换个角度来看： 我们的 IO Monad 只是提供了一些 IO 操作的步骤，并没有真正的进行 IO，真正的 IO 操作是在 runIO 里面才被执行的。这个有点 IOC 的意思，熟悉数据库的老大可能就笑了，这个 IO Monad 不就是的 redo log 或 commit log 吗。先记下操作步骤，具体把数据写入 B-Tree 是等另一个进程 (runIO) 去做的。</p>
<h2 id="一点说明">一点说明</h2>
<p>上面的 Free Monad 是代数中的<a href="http://www.haskell.org/haskellwiki/Free_structure">Free Structure</a> 在 Haskell 中的对应物。其实简单的理解 Free BasicIO 就是 BasicIO 的一个列表 : <code>[BasicIO]</code>.</p>
<p>PS: Haskell 里面的这伙人真是变态，一个个仗着自己的医生(Doctor)头衔，写个代码都是各种抽象代数，范畴学的，绕到云里雾里。 最让人生气的是还能运行。。。</p>
<h2 id="参考文献">参考文献</h2>
<p>1.<a href="http://www.haskellforall.com/2012/07/purify-code-using-free-monads.html">Haskell for all: Purify code using free monads</a></p>]]></summary>
</entry>
<entry>
    <title>在 Haskell 中使用 Continuation 实现单线程并发控制</title>
    <link href="http://veryr.com/posts/continuation-based-thread-in-haskell/" />
    <id>http://veryr.com/posts/continuation-based-thread-in-haskell/</id>
    <published>2012-08-23T00:00:00Z</published>
    <updated>2012-08-23T00:00:00Z</updated>
    <summary type="html"><![CDATA[<p>之前在 <a href="http://scheme.com/tspl4/further.html#./further:h3">Section 3.3. Continuations</a> 看到 Scheme 实现的一个用 call/cc 模拟的多任务程序, 还挺好玩的:</p>
<pre lang="scheme"><code>
    (define lwp-list &#39;())
    (define lwp
      (lambda (thunk)
        (set! lwp-list (append lwp-list (list thunk)))))

    (define start
      (lambda ()
        (let ([p (car lwp-list)])
          (set! lwp-list (cdr lwp-list))
          (p))))

    (define pause
      (lambda ()
        (call/cc
          (lambda (k)
            (lwp (lambda () (k #f)))
            (start)))))

    (lwp (lambda () (let f () (pause) (display &quot;h&quot;) (f))))
    (lwp (lambda () (let f () (pause) (display &quot;e&quot;) (f))))
    (lwp (lambda () (let f () (pause) (display &quot;y&quot;) (f))))
    (lwp (lambda () (let f () (pause) (display &quot;!&quot;) (f))))
    (lwp (lambda () (let f () (pause) (newline) (f))))
    (start)
</code></pre>
<p>这个程序会不断地输出: &gt;hey! &gt;hey! &gt;hey! &gt;hey! &gt;…</p>
<h2 id="热身">热身</h2>
<p>我估摸着吧, Haskell 里的 callCC 也可以这么玩，不过 Haskell 里面没有副作用，也就没有赋值，这个 <code>set!</code> 就需要绕个弯子, 借助 IORef 来实现了。</p>
<pre lang="haskell"><code>
import Control.Monad.Cont
import Data.IORef

main = (`runContT` return) $ do
    ref &lt;- lift $ newIORef undefined
    callCC $ \k -&gt; lift $ writeIORef ref k
    lift $ putStrLn &quot;print once&quot;
    continue &lt;- lift $ readIORef ref
    continue ()
</code></pre>
<p>稍微解释一下：这个程序会不断地打印 “print once”. 程序的执行过程是这样的，callCC 把 callCC 之后的三行代码绑定到 k 上了， 然后把 k 保存到 ref 里面。 这后三行代码呢，打印一个行 “print once”, 然后把保存在 ref 里的 k 拿出来，继续执行, 跳转到 callCC 那去了。 这样就形成了一个死循环，不断打印。</p>
<h2 id="模拟">模拟</h2>
<p>接下来就简单了，依葫芦画瓢抡一个 Haskell 版本的 light weight process 了 :</p>
<pre lang="haskell"><code>
    import Control.Monad.Cont
    import Data.IORef

    pause ref = callCC $ \k -&gt; do
        lwp ref (k ())
        start ref

    start ref = do
        (t:ts) &lt;- lift $ readIORef ref
        lift $ writeIORef ref ts
        t

    lwp ref t = lift $ modifyIORef ref $ \ts -&gt; ts ++ [t]

    main = (`runContT` return) $ do
        ref &lt;- lift $ newIORef []
        lwp ref . forever $ do
            pause ref
            lift $ putStrLn &quot;Hello&quot;
        lwp ref . forever $ do
            pause ref
            lift $ putStrLn &quot;World&quot;
        start ref</code></pre>
<p>这个程序呢，不断打印 “Hello World”, 几乎就是原来 Scheme 版本的一一对应， 没啥好解释的了。</p>
<h2 id="后话">后话</h2>
<p>ps: The Scheme Programming Language 真是一本好书。 前三章就把 Scheme 编程的要素讲完了， 包括 Continuation, CPS, 宏定义等都讲透了， 后面九章就是具体解释和应用了。Kent Dybvig 端的是功力深厚，学术一流，工程能力也没话说, Chez petite 编译器不管易用性，性能都是一等一的。话说作者还把这本书公开放在网上了: http://www.scheme.com/tspl4/ , 真的是功德无量哈。SICP 固然是好书，不过里面讲 Scheme 的东西其实不多，看过 SICP 的来看这本，想必会如或至宝。SICP 练就一身内力，不过不好使出来 (小测验: 用 Scheme 编写一个文件读写的程序?), 这本 TSPL 就是教你太极招式的好书。</p>
<h2 id="参考文献">参考文献</h2>
<ol type="1">
<li><a href="http://scheme.com/tspl4">The Scheme Programming Language</a></li>
</ol>]]></summary>
</entry>
<entry>
    <title>8 皇后的 Haskell 解法</title>
    <link href="http://veryr.com/posts/queens/" />
    <id>http://veryr.com/posts/queens/</id>
    <published>2012-08-07T00:00:00Z</published>
    <updated>2012-08-07T00:00:00Z</updated>
    <summary type="html"><![CDATA[<p>八皇后谜题问的是怎样将八个皇后摆在国际象棋棋盘上. 使得任意一个皇后都不能攻击另一个皇后(也就是说, 任意两个皇后都不在同一行、同一列或者同一对角线上).</p>
<h2 id="前人的解法">前人的解法</h2>
<p>albertlee 大牛的Haskell解法：</p>
<pre lang="haskell"><code>
import Control.Monad
import Control.Monad.Writer
import Data.List
diagonal (x1,y1) (x2,y2) = x1 + y1 == x2 + y2
                        || x1 - y1 == x2 - y2
nqueens n = execWriter $ f [1..n] 1 []
    where f [] _ ps = tell [ps]
          f cs r ps = forM_ cs $ \c -&gt;
                          unless (any (diagonal (r,c)) ps) $
                              f (delete c cs) (r + 1) ((r,c):ps)
main = print $ nqueens 4
</code></pre>
<ul>
<li><a href="http://fleurer-lee.com/2009/04/03/haskellqiu-jie-nhuang-hou-wen-ti.html">haskell求解n皇后问题</a> : fleuria 大牛的解法</li>
<li><a href="http://www.iteye.com/topic/106747">用 Python 秒掉八皇后问题！</a> : 众多大牛的解法.</li>
</ul>
<h2 id="有没有简单点的">有没有简单点的</h2>
<p>我愚钝，没看懂。只好自己也想一个解法：</p>
<pre><code>import Data.List
queens n = filter valid $ map (zip ([1..n])) $ permutations [1..n]
valid [] = True
valid ((a,b):xs) = all (\(x,y) -&gt; abs(a-x) /= abs(b-y)) xs &amp;&amp; valid xs

--6 皇后
*Main&gt; queens 6
[[(1,2),(2,4),(3,6),(4,1),(5,3),(6,5)],[(1,5),(2,3),(3,1),(4,6),(5,4),(6,2)],[(1,3),(2,6),(3,2),(4,5),(5,1),(6,4)],[(1,4),(2,1),(3,5),(4,2),(5,6),(6,3)]]</code></pre>
<p>运行的还是挺慢的. 不过代码应该很好懂, 我再解释一下: <code>map (zip ([1..n])) $ permutations [1..n]</code>生成所有皇后可能的排列, 用<code>filter valid</code>筛选出皇后之间没有冲突的就行了.</p>
<h2 id="参考文献">参考文献</h2>]]></summary>
</entry>
<entry>
    <title>Monad 的意义</title>
    <link href="http://veryr.com/posts/monad-purpose/" />
    <id>http://veryr.com/posts/monad-purpose/</id>
    <published>2012-07-07T00:00:00Z</published>
    <updated>2012-07-07T00:00:00Z</updated>
    <summary type="html"><![CDATA[<h2 id="haskell-的意义">Haskell 的意义</h2>
<p>学习 haskell, 基本上大家的第一个反应是学这东西有什么用? 也是, 学习一个东西之前知道这玩意有啥用, 才有动力去学. 想当年, 刚开始学线性代数的时侯, 矩阵变换来变换去, 我就一直耿耿于怀: 变来变去搞什么名堂, 有啥子用? 因此, 线性代数就没学好. 考试考完就全忘了. 后来才发现这玩意用处还不小: 可以解多元方程, 可意做图形学上的空间变换, 重新捡起书本, 我才对线性代数有了点印象. 学习 Haskell 有甚么用处呢. 现在想来, 用处也不大, 主要还是兴趣. Haskell 是一门很优美的语言, 虽然也有一些来源于兼容性的妥协, 但是大体上而言, Haskell 简单, 一致, 正交, 静态类型, 高性能, 基本符合个人对一门完美编程语言的要求. Monad 的意义</p>
<p>任何学习 Haskell 的一大成就或者说一大障碍就是 Monad. 好多人学 Haskell 学到 Monad 这一章不禁疑窦丛生: 这劳什子做什么的, 未啥别的语言里面都没遇到过? 下面我就试试来说说 Monad 有甚么意义.</p>
<h2 id="抽象是程序设计的根本方法">抽象是程序设计的根本方法</h2>
<p>CPU 是电路的的抽象, 汇编是 CPU (硬件) 抽象, 操作系统(系统调用)是汇编的抽象. C 语言是操作系统的抽象.</p>
<p>当程序设计发展到今天, 一个人不太可能象 Donald E. Knuth 一样通晓所有算法. 不太可能象 Bill Joy 一样 3 天写出个操作系统. 各种繁复的功能和硬件被抽象成了几个类库让大家去调用. 大家只要知道类库怎么使用就行了, 不需要知道其实现的原理.</p>
<h2 id="haskell-的抽象方法-functor">Haskell 的抽象方法 : Functor</h2>
<p>Haskell 可以使用 ADT 做数据抽象, 例如:</p>
<pre><code>data Maybe a = ...
data [a] = ...
data IO a = ...</code></pre>
<p>代表的分别是 可能不存在的 a, a 类型的一个列表, a 类型的一个 IO. 具体 <code>Maybe</code>, <code>[]</code>, <code>IO</code> 是怎么定义的实际上我们都不需要关心.</p>
<p>假设我们不知道<code>Maybe</code>, <code>[]</code>, <code>IO</code> 的内部结构, 我们可以对其进行操作吗? 答案是可以. 但是需要该抽象数据类型满足一个条件: 它必须是一个 <code>Functor</code>.</p>
<pre><code>class Functor f where
fmap :: (a -&gt; b) -&gt; f a -&gt; f b</code></pre>
<p>fmap 这个函数有甚么意义呢? fmap将一个函数从一个域变换到 f (f 可以是 <code>Maybe</code>, <code>[]</code>, <code>IO</code> , …)域. 比如我们在 Int 上有一个后继数函数 succ. 那么我们就可以将其变换到 Maybe 域:</p>
<pre><code>fmap succ (Just 1) == Just 2
fmap succ Nothing == Nothing
m1 = Just 10
m2 = Nothing
fmap succ m1
fmap succ m2</code></pre>
<p>可以将其变换到List 域:</p>
<pre><code>fmap succ [1,2,3] == [2,3,4]
fmap succ [] == []</code></pre>
<p>可以将函数其变换到IO 域:</p>
<pre><code>fmap reverse getLine</code></pre>
<p>我们完全不用关心m1, m2, Just 10, getLine 的内部结构是怎么样的, 我们就可以对其内容进行操作了.</p>
<p>我们如果有 <code>Int, Double, Float, String</code> 上的函数, 通过 fmap , 我们不费吹灰之力就有了 <code>Maybe Int, Maybe Double, Maybe String, [Int], [Double], [String], IO Int , IO String , Writer w Int, Reader r String, State s Double</code> … 上的函数. 这就是抽象的威力.</p>
<h2 id="数据的映射-appicative">数据的映射 :: Appicative</h2>
<p>上面讲到fmap 将函数 <code>a -&gt; b</code> 变换成 <code>f a -&gt; f b</code>. 假如 <code>f</code> 是完全抽象的， 我们怎么的到一个 <code>f a</code> 呢? 这就不仅要变换函数, 还要变换数据. 这就是 Applicative class要解决的问题.</p>
<pre><code>class Functor f =&gt; Applicative f where
  pure :: a -&gt; f a
  &lt;*&gt; :: f (a -&gt; b) -&gt; f a -&gt; f b</code></pre>
<p>先来看 pure. pure 可以将一个 a 变换成 <code>f a</code> , 例如:</p>
<pre><code>pure 1 == Just 1
pure 1 == [1]
pure &quot;type this string&quot; -- == getLine 输入 &quot;type this string&quot;</code></pre>
<p>函数实际上也是数据，那么 <code>pure succ</code>　也是可以的. 但是 pure succ 的类型是 <code>f (Int -&gt; Int)</code>. 这个函数我们能拿来干什么呢. 貌似啥都干不了, 因为这个函数被包裹在 f 里面了, 我们不能把他拿出来，不能喂给他一个 Int, 吐出一个Int.</p>
<p>这时候 <code>&lt;*&gt;</code> 就很有用了. 它能够将 <code>f(a -&gt; b)</code> 这个数据变成一个 <code>f a -&gt; f b</code> 的函数. 有了这个函数实际上我们都可以不需要fmap了因为:</p>
<p>pure　把一个函数 <code>a -&gt; b</code> 变换成 <code>f(a -&gt; b)</code>, <code>&lt;*&gt;</code> 把 <code>f(a -&gt; b)</code> 变换成 <code>f a -&gt; f b</code>. 两个一结合:</p>
<pre><code>(&lt;*&gt;) . pure :: (a -&gt; b) -&gt; f a -&gt; f b</code></pre>
<p>再回顾下 fmap 的类型:</p>
<pre><code>fmap :: (a -&gt; b) -&gt; f a -&gt; f b</code></pre>
<p>因此:</p>
<pre><code>fmap == (&lt;*&gt;) . pure</code></pre>
<p>到此, 我们已经能加任意类型 a, b 以及他们直接的函数 <code>a -&gt; b</code> 转换到 f 域上了.</p>
<p>现在我们就可以对任意 f 域里面的数据进行操作了. 例如对 IO a :</p>
<pre><code>-- t.hs
import Control.Applicative
import Data.List(sort)

(==&gt;) :: Applicative f =&gt; f a -&gt; (a -&gt; b) -&gt; f b
a ==&gt; g = fmap g a

main= getLine ==&gt; words ==&gt; map read ==&gt; (sort::[Int] -&gt; [Int])</code></pre>
<p>main 函数把 <code>getLine :: IO String</code> 变成有序的 <code>IO [Int]</code>, 在我们完全不知道 IO a 的内部构造的条件下.</p>
<p>运行一下:</p>
<pre><code>[root@myhost:tmp]$ ghci t.hs
GHCi, version 7.4.1: http://www.haskell.org/ghc/  :? for help
Loading package ghc-prim ... linking ... done.
Loading package integer-gmp ... linking ... done.
Loading package base ... linking ... done.
[1 of 1] Compiling Main             ( t.hs, interpreted )
Ok, modules loaded: Main.
*Main&gt; main
1 3 2 4
[1,2,3,4]
*Main&gt;</code></pre>
<h2 id="两个世界之间的联系-monad">两个世界之间的联系: Monad</h2>
<p>到目前为止, 我们接触到的从世界 a 到 f a 的函数只有 return 一个.</p>
<p>实际上这种转换函数有很多．</p>
<p>假如我们要有很多 <code>a -&gt; f a</code> 的函数，　怎么把它复合合起来呢？</p>
<p>假如我们有这个三个函数 检查输入是否是个数，是个非负数，是个偶数 :</p>
<pre><code>import Control.Applicative

parseInt :: String -&gt; Maybe Int
parseInt s = let xs = reads s in if null xs then Nothing else pure.fst.head $ xs

notNegative :: Int -&gt; Maybe Int
notNegative i = if i &lt; 0 then Nothing else pure i

notOdd :: Int -&gt; Maybe Int
notOdd x = if mod x 2 == 0 then pure x else Nothing</code></pre>
<p>最简单的, 我们采用Applicative 函数去复合他们</p>
<pre><code>checkArg :: String -&gt; Maybe (Maybe Int)
checkArg arg= (fmap $ fmap notOdd) $ (fmap notNegative) (parseInt arg)
-- checkArg &quot;1234&quot; == Just (Just 1234)
-- checkArg &quot;-1&quot; == Just Nothing
-- checkArg &quot;abc&quot; == Nothing</code></pre>
<p>问题来了. 不好复用. 多几层检查的话我们的函数签名就要变成 <code>Maybe (Maybe (Maybe (Maybe (Maybe ...))))</code> 了, 那就是 Lisp 了. :D</p>
<p>因此我们需要一个把 Maybe (Maybe Int) 变成 Maybe Int 的一个机制. 当当当:</p>
<pre><code>class Applicative m =&gt; Monad m where
  join :: m (m a) -&gt; m a</code></pre>
<p>这就是所谓的 Monad 了.</p>
<p>上面的例子, 就变成这样:</p>
<pre><code>checkArg2 :: String -&gt; Maybe Int
checkArg2 = join.fmap notOdd.join.fmap notNegative.parseInt</code></pre>
<p>后来呢, 人们嫌每次函数复合都写 join.fmap 太费劲, 于是就整了个语法糖:</p>
<pre><code>(&gt;&gt;=) :: Monad m =&gt; m a -&gt; (a -&gt; m b) -&gt; m b
m &gt;&gt;= f = join $ fmap f m</code></pre>
<p>于是</p>
<pre><code>checkArg3 arg = parseInt arg &gt;&gt;= notNegative &gt;&gt;= notOdd</code></pre>
<p>顺眼多了吧.</p>
<h2 id="参考文献">参考文献</h2>
<ol type="1">
<li><a href="http://www.iteye.com/topic/147443">回albertLee:关于Category Theory 和Monad</a></li>
<li><a href="http://yi-programmer.com/2010-04-06_haskell_and_category_translate.html">Haskell与范畴论</a></li>
</ol>]]></summary>
</entry>

</feed>
